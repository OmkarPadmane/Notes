for learning k8:
- https://killercoda.com/playgrounds/scenario/kubernetes
- https://labs.play-with-k8s.com/

orchestration : clustering of any no. of containers running on different network.

- Kubernetes is an open source container orchestration platform that automates many of the manual processes 
  involved in deploying, managing, and scaling containerized applications.
- Kubernetes is also known as "k8s", with the 8 standing for the number of letters between the “K” and the “s”.
- It is a platform for managing containers, which bundle the code, configuration, and dependencies of an application, 
  allowing it to run as an isolated process. 
- Each application gets its own containers, which are grouped into Kubernetes pods.
- Kubernetes can run on bare metal servers, virtual machines, public cloud providers, private clouds, and hybrid cloud environments.

- Kubernetes controls Pods not container.
- Kubernetes uses master-slave / Client-server architecture. 
- Google developed the k8 and later they made it open source. Now Kubernetes is a project of the Cloud Native Computing Foundation (CNCF).
- All the cloud provider supports k8.

- problems before k8 for managing container:
  - Containers can't communicate with each other.
  - Auto scalling and load balancing was not possible.

- features of k8:

1) Auto-scaling. Automatically scale containerized applications and their resources verically or horizontally based on usage.
   - vertical: Assigns more resources, like CPU or memory, to the pods that are already running.   
   - Horizontal: Adds or removes pods to scale capacity.

2) Load balancing: the process of distributing network traffic across multiple servers or pods to ensure workload.
3) Platform Independent
4) Fault Tolerance: the ability of a cluster to continue operating when some of its components fails, ex. pod
5) Rollback: the concept of maintaining multiple versions of your application. 
6) Health monitoring of containers
7) Batch execution: the process of running tasks without user intervention. 

Deployment:
- It is collection of pods running in cluster which belongs to the same application.

Pod:
- A pod is the smallest execution unit in Kubernetes. Which runs container inside it.
- Kubernetes pod can have multiple containers, but the most common use case is to have one container per pod.
- In kuberbetes an IP address is assign to Pod not to container.
- If pod gets destroyed then it can't be restrated, new pod with new ip is get created.
- When pod gets created it gets schedule to run on node, by default k8s create pod on any node until you specify the node.

- Why one container per pod?
  when there are multiple container they are tightly coupled. in that case if any container fails it affects the other containers and it can led to pod destruction.
  (tightly coupled: two or more components are depend on each other to function properly)

- Control plane: It is set of components that manage the cluster's state and coordinate the nodes, ensuring applications run as intended.
  - It manages clusters and resources such as worker nodes and pods. 

- Control plane components:
1) Master

  - API server: The application programming interface (API) server in K8 is the interface used to manage, create and 
    configure Kubernetes clusters and serves as the entry point for all commands and queries.
    - Every component communicate with other components through API-server. 

  - etcd (key-value): It store all data relating to the Kubernetes cluster in a key-value.
    - etcd manages the configuration data, state data and metadata.
    - etc: folder in Linux that contains configuration files for a single system
    - d: Stands for "distributed"
    - The configuration for etcd itself is typically found in /etc/kubernetes/manifests/etcd.yaml, and its data is stored in a directory /var/lib/etcd

  - Controller-manager (actual state = desired): 
    - It manages resources, pods or service in kubernetes. Communicates with the API server and maintains the the desired state of the cluster.
    - If you are using Cloud platform for k8 then Cloud-controller-manager is their. 

  - Scheduler (action): It creates pods and selects nodes for them to run on. 
    - The scheduler considers resource availability and allocation restraints, hardware and software requirements, and more. 
 
2) Node

  - Kubelet: Kubelet is a software agent that receives and runs orders from the master node and helps to ensure that containers are running in a pod. 
  - Kube-proxy:  A network proxy that runs on each node in a cluster to maintain network rules and allow communication.
  - Container manager: Service used for containerization, ex. Docker


- Installation:
  http: The Kubernetes API is a programmatic interface that uses HTTP to allow users,
    cluster parts, and external components to communicate with each other. 
  docker: Containerization
  gpg key: A GPG key is used for secure communication and data encryption in Kubernetes.
  kubernetes pacakges: 
    kubeadm:  Kubeadm is a tool used to build Kubernetes (K8s) clusters.
    kubectl: allows you to run commands to create and run a new pod with a container
    kubernetes-cli: a command-line tool that allows users to interact with Kubernetes clusters
  
  Bootstrapping is the process of creating a new Kubernetes cluster from scratch and getting it up and running.
  kubeadm init: initializes a Kubernetes control-plane node

Services:
- Service defines a logical set of Pods and a policy by which to access them over the network, either within the Kubernetes cluster or externally to the outside world.
- A Kubernetes Service provides a virtual static IP address (ClusterIP) that enables communication with a Pods within the Kubernetes cluster's network.

Types:
- ClusterIP service:
  - ClusterIP is the default type of service, Kubernetes assigns a cluster-internal IP address to ClusterIP service.
    This makes the service only reachable within the cluster.
  - You cannot make requests to service (pods) from outside the cluster.
  - ex. communication between the front-end and back-end components of your app.

- NodePort:
  - A NodePort is a type of service that lets you expose the pod to outside the cluster. 
  - This is one of the most basic ways to publicly expose a pod. 
  - NodePort service opens a port from the range of port 30,000 to 32,767 where the pod can be accessed.
    It means any request to your cluster on that port gets forwarded to the service.

- LoadBalancer:
  - LoadBalancer service is an extension of NodePort service. 
  - LoadBalancer service distributes the traffic between the pods that are targeted by the service. 
  - It integrates NodePort with cloud-based load balancers.
  - LoadBalancer is the Service type you should normally use when you need an application to be accessible outside Kubernetes.

 
Commands:

- kubectl get nodes    -- list nodes
- kubectl describe node node-name    -- detailed information about a specific node

- create pod and container in it using yml
-  vim pod1.yml
    kind: Pod                              
    apiVersion: v1                     
    metadata:                           
      name: testpod                  
    spec:                                    
      containers:                      
        - name: c1                     
          image: ubuntu              
          command: ["/bin/bash", "-c", "while true; do echo Hello-Bhupinder; sleep 5 ; done"]
      restartPolicy: Never         # Defaults to Always

- kind: specifies the type of Kubernetes object you are defining
- apiVersion: v1 
    - tells Kubernetes how to interpret the YAML file.
  - Why is apiVersion is mention ?
    - Kubernetes is constantly evolving, and new features and changes are introduced over time. 
      These changes can sometimes involve modifications to the structure or behavior of Kubernetes objects. 
      To ensure backward compatibility and prevent unexpected behavior, Kubernetes uses API versioning.   

- restartPolicy: Pods have an optional field called restartPolicy, where you can define the Pod’s behavior if it fails. 
    three options:
    - Always: is the default setting, and tells Kubernetes to restart the Pod after its containers stop, 
      regardless of whether the containers return a successful or failed exit code.
    - Never: means Kubernetes won’t restart the Pod once it’s finished running.
    - OnFailure: only restart a container only if the container process exits with an error.


- kubectl apply -f pod1.yml   -- create pod using manifest
- kubectl get pods   -- list pods
- kubectl describe pod pod-name    -- detailed information about a specific pod
- kubectl get pods -o wide    --  tabular overview of Pods
- kubectl logs -f pod-name   -- to see what is going in container  
  or  kubectl logs -f pod-name -c con-name    -- -f: follow, -c: container

- kubectl delete pod pod-name

- creatinng multiple container in pod:
    kind: Pod                              
    apiVersion: v1                     
    metadata:  
      name: testpod
    spec:                                    
      containers:                      
        - name: c1                     
          image: ubuntu              
          command: ["/bin/bash", "-c", "while true; do echo Hello-Bhupinder; sleep 5 ; done"]
        - name: c2
          image: ubuntu              
          command: ["/bin/bash", "-c", "while true; do echo Hello-Bhupinder; sleep 5 ; done"]
      restartPolicy: Never         # Defaults to Always

- kubectl logs pod-name --all-containers    -- to see what is going in mtuliple containers  
- kubectl exec pod-name -it -c con-name -- /bin/bash    -- to go inside container

- environment variable:

    kind: Pod                              
    apiVersion: v1                     
    metadata:  
    spec:                                    
      containers:
        name: c1
        env:  
          - name: FNAME
            value: Omkar
      restartPolicy: Never         

  - to access it go inside container use echo $var-name

- Port expose:

  kind: Pod                              
      apiVersion: v1                     
      metadata:  
      spec:                                    
        containers:
          name: c1 
          ports:
            - containerPort: 80
 
    - to access it curl pod-ip:80


Labels: Labels are metadata that can be attached to Kubernetes objects like pods, nodes, and deployments. 
  - It is key-value pairs that is used to identify and organize these objects in large clusters. 
  - Labels allow users to quickly and efficiently select and manage groups of objects that share specific characteristics.
  - ex. a label might be used to specify the environment that a particular pod is running in (e.g., test, stage, or prod). 
  

    kind: Pod                              
    apiVersion: v1                     
    metadata:                           
      name: testpod 
      Labels:
        env: development
    spec:                                    
      containers:                      
        - name: c1                     
          image: ubuntu              
          command: ["/bin/bash", "-c", "while true; do echo Hello-Bhupinder; sleep 5 ; done"]
      restartPolicy: Never         # Defaults to Always

  cmd: 
- kubectl label object obj-name key=value    -- set label to objects[ pods, nodes, and deployments]
- kubectl label pods pod-name env=development  -- set label to pod
- kubectl get pods --show-labels    -- view labels
- kubectl get pods -l env=development    -- list pod matching a label
- kubectl get pods -l env!=development    -- list pod not matching a given label
- kubectl delete pod -l env=development    -- delete pod matching a label

Selectors:
  - Label selectors allow you to select and manage groups of objects.

Namespace:
  - Namespace is a way to logically partition a single physical Kubernetes cluster into multiple virtual clusters. 
  - Names of resources need to be unique within a namespace, but not across namespaces.
  - Namespaces provide logical isolation between different teams, projects, or environments within the same cluster.
  - Namespace provides the scope for Pods, Services, and Deployments in the cluster.



